

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{biblatex} %Imports biblatex package
\usepackage[dvipsnames]{xcolor}
\usepackage{caption}
\usepackage{float}


\addbibresource{biblo.bib} %Import the bibliography file

\title{bachelorproject}
\author{Ahmad Othman}
\date{April 2022}

\begin{document}

\maketitle

\newpage

\begin{abstract}
Test abstract

\verb|asdqweasddddddddddddeq|

\end{abstract}

\newpage

\tableofcontents
%\listoffigures
%\listoftables

\newpage
\section{Introduction}
%Kontekst (hvor er vi henne i datalogien?) \\
%Motivation for problemstillingen \\
%Historik (forskningsresultater, med ref. til litteratur) \\
%I dette projekt vil vi.... (the reader is now in position to understand this, based on the previous three points)

%Indsnævre (movtivation til compression) ind til Burrow Wheeler transform og bzip2, og så dette projekt vil vi....
%komprimerings faktor? 

% There is a higher demand for storing data than ever before
We are storing and transmitting more and more data every year and as our demand for storing and transmitting data increases so does our demand for better data compressors. % TODO, as our demand for data storage and data transmission ?
% TODO: There is no maximum-data required peak in sight?.
There are many advantages to being able to compress a message efficiently. Among these advantages is that we are able to better utilize the storage capacity for both short and long term data storage. This also has benefits in data transmission. By reducing the length of the message we intend to send, we reduce the amount of time needed to send it.
% TODO: Maybe something about compressing to search faster?
% In that case, edit below: "..very clear economic AND SOCIAL incentives.."
For these reasons there are very clear economic and technological incentives to research subjects relating to data compression and to continuously develop better techniques that serve this purpose.
\\
Compressors work by inputting a file, processing it, and then outputting an encoded file. This encoded file is generally shorter than the input file, but contains enough information so that a decompressor is able regenerate the original file from the encoded file. Compressors are able to do this by removing redundant information in the data. % Er det her trivielt?
Some compressors are developed to only compress certain specific types of data, for example being developed specifically to compress only image files or only DNA files. Other compressors are developed to be more general-purpose and are able to to compress a greater variety of different types of data.

Compression algorithms are divided into two categories. These being lossy and lossless compression. Lossy compression does not require the decompressed file to match the original file exactly, but can accept some percentages of error, this results in much extreme compression ratios when compared to lossless compressors which do not allow error. This introduces a kind of compression ratio vs. error trade off for lossy compressors that is usually optional to the user.
Notable lossy compressors include the image compressor JPEG\cite{jpeg1}, audio and video compressors MPEG\cite{mpeg1}\cite{mpeg2}. However in this project we focus on lossless compression, where the requirement is that the original file can be fully recovered after decompression with no ambiguity.
When deciding which algorithm to use for lossless compression there are two major factors to consider: compression ratio and (de)compression speed. % This is why there are many different possible methods. Pareto frontier/efficiency
For some purposes we might want to compress fast but still with relatively good ratio, while other times compression ratio may be the main focus. This compression speed vs. ratio trade-off gives a pareto-frontier for compressors.
One program that is one of the champions of compression, which frequently lies on the pareto-frontier is \(bzip2\). It generally achieves better compression ratio than both \(zip\) and \(gzip\) with the trade-off of having worse results in both compression and decompression time.\cite{gzipzipbzip2} \(bzip2\) also competes with the powerful \(lzma\)-compression algorithm, which is the default compressor for the 7zip archiver.\cite{lzmaformat}\cite{ziv1977universal} The \(bzip2\) compressor generally has worse compression ratio and decompression time, but still competes since it achieves better results in terms of compression time.\cite{gzipbzip2lzma}
% TODO, skal bzip2 være kursiv? 
% Champion over, hvordan compares det? Existerende arbejde, hvordan klarer de andre algoritmer sig ift?
% Referencer generelt mangler. Der skal være mindst 10 referencer.
% Når jeg nævner lossy, 3 referencer etc.
% If the reader is more curious, etc. (nok ikke så god ide i det her tilfælde)
% Nævn burrows wheeler transform, og hvilke BWT der stammer fra den

\(bzip2\) is a general-purpose and lossless compression program originally developed and released in 1996 by Julian Seward. Since then it has been maintained by Mark Wielaard and Micah Snyder. % TODO: Verify authors and current maintainers
The compressor was developed from the result of a research report titled \texttt{A Block-sorting Lossless Data Compression Algorithm} and released in 1994 by Michael Burrows and David J. Wheeler.\cite{bwt1}\cite{manzini1999burrows} Here Burrows and Wheeler introduced a previously undiscovered reversible transform, now known as the Burrows-Wheeler Transform, which followed up by other known methods achieves good compression results.
% This has led to a bunch of variants and a bunch of compressors

In this project we explore the \(bzip2\) compressor and describe the methods it uses to achieve good compression. In 2) we describe Coding Theory?. In 3) we explore the core transform in the \(bzip2\) compressor by examining the paper describing it. Here we also explore the follow-up compression techniques that were recommended in the paper by Burrows-Wheeler after the BWT, which \(bzip2\) also uses. In 4) we examine \(bzip2\) and introduce compression techniques unique from the paper. Here we also examine the implementation of these different algorithms in the program. Lastly in 5) we analyze different results with our custom parameters for the algorithms used. We analyze this in terms of compression ratio of the Silesia Corpus\cite{silesiaCorpus}.


\section{Coding Theory}
% 
\subsection{Entropy?}
Shannon coding theorem \\
Pidgeonhole principle on compressing


\section{The Algorithm of Burrows and Wheeler}
In May 10. 1994, Michael Burrows and David J. Wheeler released a research report titled A Block-sorting Lossless Data Compression Algorithm. In this report they described a new reversible data transform that had not previously been seen, which is now named The Burrows-Wheeler transform (BWT). 
% TODO From the output of this transform they were able to , they proposed a lossless compressor which processes the data using the BWT followed by other encoding techniques.
\begin{enumerate}
	\item Burrows-Wheeler transform
	\item Move-to-front encoding
	\item Huffman encoding
\end{enumerate}
% TODO continue from above, maybe slight explanation on the other one

\subsection{Burrows-Wheeler Transform (BWT)}
% TODO: First discovered by Wheeler, but not released due to non-practical way of calculating it, they then worked together until they found a good way
The Burrows-Wheeler transform is a reversible data transform that creates a permutation of the original data. The transform is itself not a compressor but a data compression pre-processor since it has the tendency, for human-readable data, to group identical characters up in runs.
The input is a string of data \(S\) and the output is a permutation \(L\) and a number \(I\). Burrows and Wheeler showed how, if given \(L\) and \(I\), we can reconstruct the original data \(S\). 

\subsubsection{Transform}
The transform is computed conceptually by first appending a lexicographically "smallest" \(\$\) character to the end of the string. From that string we construct a matrix where each row is a cyclic shift of the string. We then lexicographically sort the rows of that matrix. The output will then be the concatenation of the characters appearing in the last column in the row-sorted matrix.

To illustrate this we give an example. We wish to perform the \texttt{BWT} on the string \(S = "abracadabra"\). We start by introducing a new character \(\$\) to \(S\) and appending it to the end of the string. \(\$\) is a character that does not previously appear in \(S\) and is lexicographically the smallest character. This gives us \(S' = "abracadabra\$"\) 
% In the lexicographically sorted alphabet \Sigma = $abcd
We now generate all cyclic shifts of \(S'\) and sort them lexicographically.

\begin{figure}[H]
    \[
        \begin{tabular}{|c|c|}
            \hline
            0 & abracadabra\$ \\ \hline
            1 & bracadabra\$a \\ \hline
            2 & racadabra\$ab \\ \hline
            3 & acadabra\$abr \\ \hline
            4 & cadabra\$abra \\ \hline
            5 & adabra\$abrac \\ \hline
            6 & dabra\$abraca \\ \hline
            7 & abra\$abracad \\ \hline
            8 & bra\$abracada \\ \hline
            9 & ra\$abracadab \\ \hline
            10 & a\$abracadabr \\ \hline
            11 & \$abracadabra \\ \hline
        \end{tabular}
        \qquad \longrightarrow \qquad
        \begin{tabular}{|c|c|}
            \hline
            11 & \$abracadabra \\ \hline
            10 & a\$abracadabr \\ \hline
            7 & abra\$abracad \\ \hline
            0 & abracadabra\$ \\ \hline
            3 & acadabra\$abr \\ \hline
            5 & adabra\$abrac \\ \hline
            8 & bra\$abracada \\ \hline
            1 & bracadabra\$a \\ \hline
            4 & cadabra\$abra \\ \hline
            6 & dabra\$abraca \\ \hline
            9 & ra\$abracadab \\ \hline
            2 & racadabra\$ab \\ \hline
        \end{tabular}
    \]
    \captionof{figure}{The cyclic shifts of \(S'\) (left) sorted lexicographically (right). The output is then the last column of the sorted cyclic shifts matrix \(L = "ard\$rcaaaabb"\) and the row number of the original string \(S'\) in the sorted cyclic shifts matrix \(I = 3\).}
\end{figure}
We observe the effect this transform had on the input string \(S="abracadabra"\) which contained zero runs of identical characters. The out string \(L="ardrcaaaabb\) however has two runs, first containing 4 a's, and second containing 2 b's.
Since we have defined each row in the matrix to be a cyclic shift of our original string, then obviously, in the unsorted matrix each row and column is a cyclic shift of \(S'\). After sorting the rows of the matrix, the rows remain cyclic shifts but the columns will no longer necessarily be the cyclic shifts of \(S'\) but they will remain a permutation of it. % TODO format sentence better?
This algorithm provides a good conceptual way to imagine and explain the \texttt{BWT} but is not used in practice since it requires constructing the entire matrix in memory, requiring \(O(n^2)\) space.

\subsubsection{BWT from Suffix Arrays} % Should this be here?
A more efficient implementation, and how the transform is computed in practice is by observing that when we lexicographically sort the rows of the matrix, the order they end up in is the same order the suffixes are in, in the suffix array. This is the case since like the suffix array of \(S\), when we sort the cyclic shifts of \(S'\) we only need to sort up to and including the \(\$\) symbol.
This means that the transform can be computed by constructing the suffix array \(SA\) of \(S\)\cite{manber1993suffix}\cite{simpson2010efficient}
\begin{equation*}
    \begin{tabular}{|c|l|}
    \hline
    i & \\ \hline
    0 & abracadabra\$ \\ \hline
    1 & bracadabra\$ \\ \hline
    2 & racadabra\$ \\ \hline
    3 & acadabra\$ \\ \hline
    4 & cadabra\$ \\ \hline
    5 & adabra\$ \\ \hline
    6 & dabra\$ \\ \hline
    7 & abra\$ \\ \hline
    8 & bra\$ \\ \hline
    9 & ra\$ \\ \hline
    10 & a\$ \\ \hline
    11 &\$ \\ \hline
    \end{tabular}
    \qquad\longrightarrow\qquad
    \begin{tabular}{|c|c|l|}
    \hline
    i & SA[i] & \\ \hline
    0 & 11 &\$ \\ \hline
    1 & 10 & a\$ \\ \hline
    2 & 7 & abra\$ \\ \hline
    3 & 0 & abracadabra\$ \\ \hline
    4 & 3 & acadabra\$ \\ \hline
    5 & 5 & adabra\$ \\ \hline
    
    6 & 8 & bra\$ \\ \hline
    7 & 1 & bracadabra\$ \\ \hline
    8 & 4 & cadabra\$ \\ \hline
    
    9 & 6 & dabra\$ \\ \hline
    10 & 9 & ra\$ \\ \hline
    11 & 2 & racadabra\$ \\ \hline
    \end{tabular}
\end{equation*}
And then the \texttt{BWT} can be constructed directly from the suffix array \(SA\) and our original string \(S\). We build the string \(L\) for each index \(i = 0 \dots |S|-1\):
\[
    L[i] = \begin{cases} 
        S[SA[i] - 1] & SA[i] > 0 \\
        \$ & SA[i] = 0 \\
   \end{cases}
\]
The character in \(L[i]\) will be the character one step left of the character at index \(SA[i]\), which is \(S[SA[i] - 1]\). When \(SA[i] = 0\) the character will be the special \(\$\) character. In the same example we will have the same string \(L = "ard\$rcaaaabb"\) and \(I = 3\).
This reduces the problem of finding the \texttt{BWT} of \(S\) to the problem of constructing the suffix array of \(S\).We can omit \(\$\) from \(L\) since we already know the value of \(I\), which will always correspond to the index in which \(\$\) appears in \(L\).

\subsubsection{Effect on data}

\subsubsection{Reverse Transform}
% Reverse transform concept then effective method
From \(L\) we can construct the sorted containing the sorted cyclic shifts. We start by adding the column \(L\) and sorting it. Then we continuously add \(L\) as a column at the front and sorting the rows. We do this until the rows have the same length as \(L\). 
\begin{equation*}
    \begin{tabular}{|c|}\hline
        a \\ \hline
        r \\ \hline
        d \\ \hline
        \$ \\ \hline
        r \\ \hline
        c \\ \hline
        a \\ \hline
        a \\ \hline
        a \\ \hline
        a \\ \hline
        b \\ \hline
        b \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        \$ \\ \hline
        a \\ \hline
        a \\ \hline
        a \\ \hline
        a \\ \hline
        a \\ \hline
        b \\ \hline
        b \\ \hline
        c \\ \hline
        d \\ \hline
        r \\ \hline
        r \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        a\$ \\ \hline
        ra \\ \hline
        da \\ \hline
        \$a \\ \hline
        ra \\ \hline
        ca \\ \hline
        ab \\ \hline
        ab \\ \hline
        ac \\ \hline
        ad \\ \hline
        br \\ \hline
        br \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        \$a \\ \hline
        a\$ \\ \hline
        ab \\ \hline
        ab \\ \hline
        ac \\ \hline
        ad \\ \hline
        br \\ \hline
        br \\ \hline
        ca \\ \hline
        da \\ \hline
        ra \\ \hline
        ra \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        a\$a \\ \hline
        ra\$ \\ \hline
        dab \\ \hline
        \$ab \\ \hline
        rac \\ \hline
        cad \\ \hline
        abr \\ \hline
        abr \\ \hline
        aca \\ \hline
        ada \\ \hline
        bra \\ \hline
        bra \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        \$ab \\ \hline
        a\$a \\ \hline
        abr \\ \hline
        abr \\ \hline
        aca \\ \hline
        ada \\ \hline
        bra \\ \hline
        bra \\ \hline
        cad \\ \hline
        dab \\ \hline
        ra\$ \\ \hline
        rac \\ \hline
    \end{tabular}
    \rightarrow
    \begin{tabular}{|c|}\hline
        a\$ab \\ \hline
        ra\$a \\ \hline
        dabr \\ \hline
        \$abr \\ \hline
        raca \\ \hline
        cada \\ \hline
        abra \\ \hline
        abra \\ \hline
        acad \\ \hline
        adab \\ \hline
        bra\$ \\ \hline
        brac \\ \hline
    \end{tabular}
\end{equation*}


The original string \(S'\)


This transformation is the core of \(bzip2\)

\subsection{Move-to-front Encoding}
% TODO improve this
% TODO reference the papers of MTF
After the \texttt{BWT} the string is expected to have 
The Move-to-Front Encoding (MTF) is the third algorithm used in the \texttt{bzip2} compressor. It is a reversible lossless encoder that, like the BWT, does not change the size of input. It takes advantage of the expected output of the \texttt{BWT} to further processes the data.

\subsubsection{Encoding}
The \texttt{MTF} encodes each character by replacing it with its index in a list containing the alphabet. The list is then updated each time, where that character is popped from its position in the list, and moved to the front of it.
%\begin{algorithm}[H]
%    \caption{Move-to-front Encode}\label{alg:cap}
%    \begin{algorithmic}[1]
%        \Procedure{MTF\_Encode}{bytes}
%            \State \(\Sigma \gets [0, 1, 2, \dots , 255]\)
%            \For{i = 0 \dots bytes.length - 1}{
%                \State $code \gets$ \Sigma.index(bytes[i])
%                \State \(bytes[i] \gets code\)
%                \Sigma.remove(bytes[i])
 %               \Sigma.prepend(bytes[i])
%            }
%        \EndProcedure
%    \end{algorithmic}
%\end{algorithm}
We illustrate this with an example. Continuing from our example from the \texttt{BWT}, we wish to \texttt{MTF} encode the string \(L = "ardrcaaaabb"\). We initialize our alphabet list such that it contains the unique symbols appearing in \(L\) sorted in alphabetical order \(\Sigma=[a, b, c, d, r]\).
The same initial symbols list used when encoding is required for decoding, therefor it is usually implemented to be the same in the encoder/decoder implementation. 
Now we iterate through \(L\). For each character in \(L\), we replace it by the index in which it appears in the list. Then we pop that character from its position in the list and preprend it to the front of the list.
{\small 
    \begin{align*}
        |ardrcaaaabb \quad \quad\quad [a, b, c, d, r] \\[-4pt]
        0|rdrcaaaabb \quad \quad\quad [a, b, c, d, r] \\[-4pt]
        04|drcaaaabb \quad \quad\quad [r, a, b, c, d] \\[-4pt]
        044|rcaaaabb \quad \quad\quad [d, r, a, b, c] \\[-4pt]
        0441|caaaabb \quad \quad\quad [r, d, a, b, c] \\[-4pt]
        04414|aaaabb \quad \quad\quad [c, r, d, a, b] \\[-4pt]
        044143|aaabb \quad \quad\quad [a, c, r, d, b] \\[-4pt]
        0441430|aabb \quad \quad\quad [a, c, r, d, b] \\[-4pt]
        04414300|abb \quad \quad\quad [a, c, r, d, b] \\[-4pt]
        044143000|bb \quad \quad\quad [a, c, r, d, b] \\[-4pt]
        0441430004|b \quad \quad\quad [b, a, c, r, d] \\[-4pt]
        04414300040| \quad \quad\quad [b, a, c, r, d]
    \end{align*}
}
The output of the \texttt{MTF} with input \(L = "ardrcaaaabb"\) is then \("04414300040"\). The usage of \texttt{MTF} encoding after the \texttt{BWT} step was proposed by Burrows and Wheeler. This step is useful since after the \texttt{BWT} step, our assumption is that the data will contain runs of identical characters. In this case the \texttt{MTF} will replace these runs of identical characters by a specific number followed by many zeros. This means that after the \texttt{MTF} step, our data should predominantly contain zeros with occasional breaks of different numbers.
% This algorithm takes O(nk), where n is size of the input and k is a constant, usually 256.



% TODO we can initialize the alphabet better so it has more zeros

\subsubsection{Decoding}
Decoding the MTF is a similar procedure to the encoding. We initialize the exact same alphabet list that we used for the encoding \(\Sigma = [a, b, c, d, r]\). Each number in the encoded string represents the index of the original character in the list. So we replace each number by the character in that position in the list and move that character to the front of the list.  
\begin{align*}
    |04414300040 \quad \quad\quad [a, b, c, d, r] \\
    a|4414300040 \quad \quad\quad [a, b, c, d, r] \\
    ar|414300040 \quad \quad\quad [r, a, b, c, d] \\
    ard|14300040 \quad \quad\quad [d, r, a, b, c] \\
    ardr|4300040 \quad \quad\quad [r, d, a, b, c] \\
    ardrc|300040 \quad \quad\quad [c, r, d, a, b] \\
    ardrca|00040 \quad \quad\quad [a, c, r, d, b] \\
    ardrcaa|0040 \quad \quad\quad [a, c, r, d, b] \\
    ardrcaaa|040 \quad \quad\quad [a, c, r, d, b] \\
    ardrcaaaa|40 \quad \quad\quad [a, c, r, d, b] \\
    ardrcaaaab|0 \quad \quad\quad [b, a, c, r, d] \\
    ardrcaaaabb| \quad \quad\quad [b, a, c, r, d]
\end{align*}
Which gives us the decoded string \("ardrcaaaabb"\) from the encoded string \("04414300040"\).


\subsection{Huffman Encoding}
The last step of the algorithm suggested by Burrows and Wheeler is the usage of huffman

\section{Bzip2}
\texttt{bzip2} is an open-source file compression program. It is a general-purpose compressor that combines 5 self-contained layers of compression techniques, these layers are. 

It is considered a powerful compressor, in general showing better results than the more commonly-used \texttt{gzip} and \texttt{zip} in terms of compression ratio, but worse in terms of de(compression) speed.

\begin{enumerate}
	\item Run-length encoding (RLE 1)
	\item Burrows-Wheeler transform (BWT)
	\item Move-to-front encoding (MTF)
	\item Run-length encoding (RLE 2)
	\item Huffman encoding (using multiple Huffman trees).
\end{enumerate}

The core of \texttt{bzip2} is the Burrows-Wheeler transform. uses several methods, the core of which being the Burrows-Wheeler transform. The techniques used in \texttt{bzip2} are loosely based on the research article by burrows and wheeler % TODO: place this somewhere

\subsection{Run-length Encoding}
The Run-length Encoding (RLE) is an important step in the compression performance of the \texttt{bzip2} compressor.
The encoding can be applied
For any type data, if there are sequences of identically repeating characters, there is no need to store all the characters in those sequences of repeating characters. The \texttt{RLE} replaces those sequences with one character identifying what character that sequence is comprised of, and then amount of characters appearing in that sequence.\\
We show an example of \texttt{RLE}. Assume that we wish to encode "aaaaabbbbcaaaa" using \texttt{RLE}. We know that the string can be represented as being a string consisting of 5 \(a\)'s, 4 \(b\)'s, 1 \(c\) and 4 \(a\)'s. We can write this as the following
\[
aaaaabbbbcaaaa \rightarrow 5a4bc4a.
\]
This does not remove any information of the data but, only sequences data in order We can reduce this data and simply write the amounts. 

% Here we would know that there are Xas, Ybs, etc.
The \texttt{RLE} step tries to take advantage of the output of the \texttt{MTF} step. Since as previously mentioned, from the output of the \texttt{MTF} step we can expect our data to contain many sequences of consecutive zeros. The \texttt{RLE} will remove those consecutive zeros and instead write the amount of zeros that will appear in that sequence of zeros.

% Successor to bzip1 because of patent

\subsection{Multiple Huffman Trees}
The \texttt{bzip2} compressor uses multiple Huffman trees in order to efficiently compress the data. The amount of trees it uses is entirely dependent on the size of the data but can be between 2 and 6.
% TODO: Does below make sense?
Huffman encoding guarantees symbol-code optimality for the entire data, but it is not necessarily optimal for individual segments of the data. For this reason, \texttt{bzip2} creates \(n\) initial Huffman trees, that are optimal for symbol partition of the entire data in terms of their frequencies. For example, Huffman tree numbered 0 will initially have optimal codes for the symbols in the interval [0, 1], and then Huffman tree numbered 1 will have optimal codes for [2, 8] etc.
For each interval, the aim for each Huffman tree is initially to be optimal for \(\frac{100}{n}\%\) of the symbol frequencies. \\
After this initialization process iterate \texttt{BZ\_N\_ITERS} (which is per default 4) times to improve the trees. For each iteration, we iterate each 50 symbol length segment and find the current cheapest Huffman tree for that segment. That segments symbol frequencies get assigned to its cheapest Huffman tree, and before next iteration we generate the Huffman codes for those frequencies using the Huffman algorithm.
This gives a way for each Huffman tree to specialize in specific segments of the data, only which are similar to each other in their symbol frequencies.

\section{Experiments / Analysis?}
\subsection{Experimental Setup}
%We implement the methods presented in 3 to compare compression ratio.
% The focus is compression ratio, not speed
\subsection{Run-length encoding}

\subsection{Multiple Huffman}

\section{Conclusion}
In this thesis, we did.... \\
Natural future work could include..


\printbibliography %Prints bibliography

\end{document}
